{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "import equinox as eqx\n",
    "from jax import Array, numpy as jnp, random as jr, vmap, nn\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pets.envs import AtariEnv\n",
    "from pets.model import Ensemble\n",
    "from pets.dataset import Dataset\n",
    "\n",
    "from pets.train import train_step\n",
    "from pets.agent import sample_episodes, sample_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(env, model, stats, key):\n",
    "    states, actions, rewards, next_states = sample_trajectory(env, rollout_length)\n",
    "    states, actions = states[rollout_offset:, None, :], actions[rollout_offset:, None, :]\n",
    "    pred_states = model.rollout(states[0], actions, stats, key=key)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(6, 4))\n",
    "    for idx, ax in enumerate([(0, 0), (0, 1), (1, 0), (1, 1)]):\n",
    "        axes[ax].plot(states[:, 0, idx], c=\"r\")\n",
    "        axes[ax].plot(pred_states[:, 0, :, idx], c=\"g\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jr.PRNGKey(0)\n",
    "batch_dim = 32\n",
    "num_train_epochs = 5\n",
    "ensemble_dim, hidden_dim = 5, 200\n",
    "rollout_length, rollout_offset = 50, 25\n",
    "num_seed_episodes, episode_length = 500, 200\n",
    "\n",
    "env = AtariEnv(\"PongDeterministic-v4\")\n",
    "state_dim, action_dim = env.observation_space.shape[0], 1\n",
    "\n",
    "dataset = Dataset(state_dim, action_dim, ensemble_dim)\n",
    "dataset = sample_episodes(env, dataset, num_seed_episodes, episode_length)\n",
    "stats = dataset.stats()\n",
    "\n",
    "model = Ensemble(state_dim + action_dim, state_dim, hidden_dim, ensemble_dim, key=key)\n",
    "optim = optax.adamw(learning_rate=1e-4, weight_decay=1e-5, eps=1e-8)\n",
    "optim_state = optim.init(eqx.filter(model, eqx.is_inexact_array))\n",
    "\n",
    "while True:\n",
    "    for _ in range(num_train_epochs):\n",
    "        for batch in dataset.batches(batch_dim):\n",
    "            model, optim_state, _ = train_step(model, batch, stats, optim, optim_state)\n",
    "\n",
    "    test(env, model, stats, key)\n",
    "\n",
    "    eqx.tree_serialise_leaves(\"../data/model.eqx\", model)\n",
    "    dataset.save(\"../data/dataset.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
