{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "from jax import numpy as jnp, random as jr, vmap, nn, lax\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pets.control import plan\n",
    "from pets.model import Ensemble\n",
    "from pets.dataset import Normalizer\n",
    "from pets.envs.atari import AtariEnv, reward_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tile = lambda x: jnp.tile(x[:, None, ...], (1, ensemble_dim, 1))\n",
    "\n",
    "def forward(model, normalizer, state, action, key):\n",
    "    inputs = jnp.concatenate([state, action], axis=-1)\n",
    "    inputs = normalizer.normalize(inputs)\n",
    "    delta_mean, delta_logvar = vmap(model)(inputs)\n",
    "    delta_std = jnp.sqrt(jnp.exp(delta_logvar))\n",
    "    delta = delta_mean + delta_std * jr.normal(key, delta_mean.shape)\n",
    "    return state + delta\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def rollout_fn(state, actions):\n",
    "    state, actions = _tile(state), vmap(_tile)(actions)\n",
    "\n",
    "    def scan_fn(carry, action):\n",
    "        state, key = carry\n",
    "        key, subkey = jr.split(key)\n",
    "        next_state = forward(model, normalizer, state, action, subkey)\n",
    "        return (next_state, key), next_state\n",
    "\n",
    "    (final_state, _), states = lax.scan(scan_fn, (state, key), actions)\n",
    "    rewards = reward_fn(states)\n",
    "    return states, rewards.mean(-1)[..., None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 0.0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "key = jr.PRNGKey(0)\n",
    "\n",
    "env = AtariEnv(\"PongDeterministic-v4\", render_mode=\"human\")\n",
    "state_dim = env.observation_space.shape[0]\n",
    "ensemble_dim, hidden_dim, action_dim, num_steps = 5, 200, 3, 70\n",
    "\n",
    "key, subkey = jr.split(key)\n",
    "model = Ensemble(state_dim + 1, state_dim, hidden_dim, ensemble_dim, key=key)\n",
    "model = eqx.tree_deserialise_leaves(\"../data/model.eqx\", model)\n",
    "normalizer = Normalizer.load(\"../data/normalizer.pkl\")\n",
    "\n",
    "(state, _), total_reward = env.reset(), 0.0\n",
    "for _ in range(num_steps):\n",
    "    key, subkey = jr.split(key)\n",
    "\n",
    "    probs, _, _ = plan(state, rollout_fn, action_dim, subkey)\n",
    "    action = probs.mean(1).argmax(-1)[0]\n",
    "\n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "    total_reward = total_reward + reward\n",
    "print(f\"reward: {total_reward}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "svae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
