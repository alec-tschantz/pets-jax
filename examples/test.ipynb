{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "from jax import numpy as jnp, random as jr, vmap, nn, lax\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pets.control import plan\n",
    "from pets.model import Ensemble\n",
    "from pets.dataset import Dataset\n",
    "from pets.envs.atari import AtariEnv, reward_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout_fn(state, action):\n",
    "    states = model.rollout(state, action, stats, key)\n",
    "    rewards = reward_fn(states)\n",
    "    return states, rewards.mean(-1)[..., None]\n",
    "\n",
    "\n",
    "def act(state):\n",
    "    probs, _, _ = plan(state, rollout_fn, action_dim, key)\n",
    "    return probs.mean(1).argmax(-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[109.  22.   0.  60. 109.  22.   0.  60.]\n",
      "[109.  16.   0.   0.   0.  -6.   0. -60.]\n",
      "[109.   8.   0.   0.   0.  -8.   0.   0.]\n",
      "[109.   2.   0.   0.   0.  -6.   0.   0.]\n",
      "[109.   0.   0.   0.   0.  -2.   0.   0.]\n",
      "[109.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[109.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[109.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[109.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[109.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[109.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[109.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[109.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[109.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[109.   0.   0.   0.   0.   0.   0.   0.]\n",
      "[109. 130. 126. 130.   0. 130. 126. 130.]\n",
      "[109. 134. 122. 134.   0.   4.  -4.   4.]\n",
      "[109. 138. 118. 138.   0.   4.  -4.   4.]\n",
      "[109. 142. 114. 142.   0.   4.  -4.   4.]\n",
      "[109. 146. 110. 146.   0.   4.  -4.   4.]\n",
      "[109. 150. 106. 150.   0.   4.  -4.   4.]\n",
      "[109. 154. 102. 154.   0.   4.  -4.   4.]\n",
      "[109. 158.  98. 158.   0.   4.  -4.   4.]\n",
      "[109. 162.  94. 162.   0.   4.  -4.   4.]\n",
      "[109. 166.  90. 166.   0.   4.  -4.   4.]\n",
      "[109. 170.  86. 170.   0.   4.  -4.   4.]\n",
      "[109. 174.  82. 174.   0.   4.  -4.   4.]\n",
      "[109. 178.  78. 178.   0.   4.  -4.   4.]\n",
      "[109. 182.  74. 182.   0.   4.  -4.   4.]\n",
      "[109. 186.  70. 186.   0.   4.  -4.   4.]\n",
      "[109. 184.  70. 184.   0.  -2.   0.  -2.]\n",
      "[109. 178.  74. 176.   0.  -6.   4.  -8.]\n",
      "[109. 170.  78. 168.   0.  -8.   4.  -8.]\n",
      "[109. 164.  82. 160.   0.  -6.   4.  -8.]\n",
      "[109. 156.  86. 152.   0.  -8.   4.  -8.]\n",
      "[109. 150.  90. 144.   0.  -6.   4.  -8.]\n",
      "[109. 142.  94. 136.   0.  -8.   4.  -8.]\n",
      "[109. 136.  98. 128.   0.  -6.   4.  -8.]\n",
      "[109. 128. 102. 120.   0.  -8.   4.  -8.]\n",
      "[109. 122. 106. 112.   0.  -6.   4.  -8.]\n",
      "[109. 114. 110. 104.   0.  -8.   4.  -8.]\n",
      "[109. 108. 114.  96.   0.  -6.   4.  -8.]\n",
      "[109. 100. 118.  88.   0.  -8.   4.  -8.]\n",
      "[109.  94. 122.  80.   0.  -6.   4.  -8.]\n",
      "[109.  86. 126.  72.   0.  -8.   4.  -8.]\n",
      "[109.  80. 130.  64.   0.  -6.   4.  -8.]\n",
      "[109.  72. 134.  56.   0.  -8.   4.  -8.]\n",
      "[109.  66. 138.  48.   0.  -6.   4.  -8.]\n",
      "[109.  58. 142.  49.   0.  -8.   4.   1.]\n",
      "[109.  56. 146.  57.   0.  -2.   4.   8.]\n",
      "[109.  64. 150.  65.   0.   8.   4.   8.]\n",
      "[109.  70. 154.  73.   0.   6.   4.   8.]\n",
      "[109.  78. 158.  81.   0.   8.   4.   8.]\n",
      "[109.  84. 162.  89.   0.   6.   4.   8.]\n",
      "[109.  92. 166.  97.   0.   8.   4.   8.]\n",
      "[109.  98. 170. 105.   0.   6.   4.   8.]\n",
      "[109. 106. 174. 113.   0.   8.   4.   8.]\n",
      "[109. 112. 178. 121.   0.   6.   4.   8.]\n",
      "[109. 120. 182. 129.   0.   8.   4.   8.]\n",
      "[109. 126. 186. 137.   0.   6.   4.   8.]\n",
      "[109. 134. 190. 145.   0.   8.   4.   8.]\n",
      "[109. 140. 194. 153.   0.   6.   4.   8.]\n",
      "[109. 148. 198. 161.   0.   8.   4.   8.]\n",
      "[109. 154. 202. 169.   0.   6.   4.   8.]\n",
      "[109. 162. 205. 175.   0.   8.   3.   6.]\n",
      "[ 109.  156.  205.    0.    0.   -6.    0. -175.]\n",
      "[109. 148. 205.   0.   0.  -8.   0.   0.]\n",
      "[109. 142. 205.   0.   0.  -6.   0.   0.]\n",
      "[109. 134. 205.   0.   0.  -8.   0.   0.]\n",
      "[109. 128. 205.   0.   0.  -6.   0.   0.]\n",
      "[109. 120. 205.   0.   0.  -8.   0.   0.]\n",
      "[109. 114. 205.   0.   0.  -6.   0.   0.]\n",
      "[109. 106. 205.   0.   0.  -8.   0.   0.]\n",
      "[109. 100. 205.   0.   0.  -6.   0.   0.]\n",
      "[109.  92. 205.   0.   0.  -8.   0.   0.]\n",
      "[109.  86. 205.   0.   0.  -6.   0.   0.]\n",
      "[109.  78. 205.   0.   0.  -8.   0.   0.]\n",
      "[109.  72. 205.   0.   0.  -6.   0.   0.]\n",
      "[109.  64. 205.   0.   0.  -8.   0.   0.]\n",
      "[109.  58. 205.   0.   0.  -6.   0.   0.]\n",
      "reward: -1.0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\"\"\" experiment parameters \"\"\"\n",
    "key = jr.PRNGKey(1)\n",
    "\n",
    "num_steps = 80\n",
    "ensemble_dim, hidden_dim = 5, 200\n",
    "\n",
    "\"\"\" environment \"\"\"\n",
    "env = AtariEnv(\"PongDeterministic-v4\", render_mode=\"human\")\n",
    "state_dim, action_dim = env.observation_space.shape[0], 3\n",
    "\n",
    "\"\"\" model \"\"\"\n",
    "model = Ensemble(state_dim + 1, state_dim, hidden_dim, ensemble_dim, key=key)\n",
    "model = eqx.tree_deserialise_leaves(\"../data/model.eqx\", model)\n",
    "\n",
    "\"\"\" dataset \"\"\"\n",
    "dataset = Dataset.load(\"../data/dataset.pkl\")\n",
    "stats = dataset.stats()\n",
    "\n",
    "\"\"\" test model \"\"\"\n",
    "(state, _), total_reward = env.reset(), 0.0\n",
    "for _ in range(num_steps):\n",
    "    action = act(state)\n",
    "    state, reward, done, truncated, info = env.step(action)\n",
    "    total_reward = total_reward + reward\n",
    "\n",
    "env.close()\n",
    "print(f\"reward: {total_reward}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "svae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
